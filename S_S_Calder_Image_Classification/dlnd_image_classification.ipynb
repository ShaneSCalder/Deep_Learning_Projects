{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe15cda6a0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return x/255\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #a = np.zeros((len(x), max(x) + 1))\n",
    "    #for i in range(len(x)):\n",
    "    #   a[i, x[i]] = 1\n",
    "    \n",
    "    #return a\n",
    "\n",
    "    \n",
    "    a = np.zeros((len(x), 10))\n",
    "    a[np.arange(len(x)), x] = 1    \n",
    "    return a\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #def neural_net_imageinput(image_shape):\n",
    "    return tf.placeholder(tf.float32, (None, *image_shape), 'x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], 'y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,None, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement Function\n",
    "    num_channels = int(x_tensor.get_shape()[3])\n",
    "    filter_weights = tf.Variable(tf.truncated_normal([*conv_ksize, num_channels, conv_num_outputs], stddev=0.05))\n",
    "    filter_biases = tf.Variable(tf.constant(0.01, shape=[conv_num_outputs], dtype=tf.float32))\n",
    "    layer = tf.nn.conv2d(input = x_tensor, filter = filter_weights, strides=[1, *conv_strides, 1], padding= 'SAME')\n",
    "    layer += filter_biases\n",
    "    layer = tf.nn.relu(layer)\n",
    "    layer = tf.nn.max_pool(layer, [1, *pool_ksize, 1], strides=[1, *pool_strides, 1], padding = 'SAME')\n",
    "    \n",
    "    #weights = tf.Variable(tf.truncated_normal([*conv_ksize, x_tensor.get_shape().as_list()[3], conv_num_outputs])\n",
    "\n",
    "    #bias =tf.Variable(tf.zeros(conv_num_outputs))\n",
    "                          \n",
    "    #conv_layer = tf.nn.conv2d(input, wieghts, strides=con_strides, padding='SAME')\n",
    "    \n",
    "    #conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    \n",
    "    #conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    #conv_layer = tf.nn.max_pool(conv_layer, ksize=pool_ksize, strides=pool_strides, padding = 'SAME')\n",
    "    \n",
    "    return layer\n",
    "       \n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    flatten_layer = tf.contrib.layers.flatten(x_tensor)\n",
    "    return flatten_layer\n",
    "\n",
    "    #return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #return tf.contrib.layers.fully_connected(x_tensor, num_outputs, activation_fn=None)\n",
    "    return tf.layers.dense(inputs=x_tensor,units = num_outputs, activation=tf.nn.relu)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function use code from above but modify\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs, activation_fn = None)\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    # Layers 1, 2, 3\n",
    "    con1 = conv2d_maxpool(x, 16,(4,4),(1,1),(2,2),(2,2))\n",
    "    con2 = conv2d_maxpool(con1, 32, (3, 3), (2, 2), (2, 2), (2, 2))\n",
    "    con3 = conv2d_maxpool(con2, 64, (3, 3), (2, 2), (2, 2), (2, 2))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flatten1 = flatten(con3)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc1 = fully_conn(flatten1, 256)\n",
    "\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    fc2 = fully_conn(fc1, 512)\n",
    "\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(fc2, 10)\n",
    "\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y:label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    validation_size = 512\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    valid_acc = session.run(accuracy, feed_dict = { x: valid_features[:validation_size], y: valid_labels[:validation_size], keep_prob: 1.0})\n",
    "    \n",
    "    print('Loss: {0} Validation Accuracy: {1}'.format(loss, valid_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 60\n",
    "batch_size = 512\n",
    "keep_probability = .8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.1759133338928223 Validation Accuracy: 0.228515625\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.0255913734436035 Validation Accuracy: 0.2109375\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.914609670639038 Validation Accuracy: 0.25\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.8775837421417236 Validation Accuracy: 0.28125\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.818974494934082 Validation Accuracy: 0.30078125\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.7659434080123901 Validation Accuracy: 0.314453125\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.7303259372711182 Validation Accuracy: 0.357421875\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.6577551364898682 Validation Accuracy: 0.365234375\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.6250492334365845 Validation Accuracy: 0.388671875\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.5620763301849365 Validation Accuracy: 0.412109375\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.5472605228424072 Validation Accuracy: 0.421875\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.5003209114074707 Validation Accuracy: 0.423828125\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.4678833484649658 Validation Accuracy: 0.423828125\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.431542158126831 Validation Accuracy: 0.44921875\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.4120776653289795 Validation Accuracy: 0.45703125\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.3719416856765747 Validation Accuracy: 0.4609375\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.3485887050628662 Validation Accuracy: 0.474609375\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.318302869796753 Validation Accuracy: 0.470703125\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.3035850524902344 Validation Accuracy: 0.470703125\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.2647541761398315 Validation Accuracy: 0.4765625\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.2361564636230469 Validation Accuracy: 0.474609375\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.2142572402954102 Validation Accuracy: 0.46875\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.1859440803527832 Validation Accuracy: 0.474609375\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.1657037734985352 Validation Accuracy: 0.47265625\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.1848065853118896 Validation Accuracy: 0.474609375\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.1287858486175537 Validation Accuracy: 0.478515625\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.0910719633102417 Validation Accuracy: 0.4765625\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.0862500667572021 Validation Accuracy: 0.470703125\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.0560108423233032 Validation Accuracy: 0.4765625\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.0218589305877686 Validation Accuracy: 0.484375\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.004963994026184 Validation Accuracy: 0.482421875\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.9855860471725464 Validation Accuracy: 0.482421875\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.9646319150924683 Validation Accuracy: 0.482421875\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.9471530914306641 Validation Accuracy: 0.4765625\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.9930756092071533 Validation Accuracy: 0.50390625\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.917451024055481 Validation Accuracy: 0.501953125\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.9430879950523376 Validation Accuracy: 0.484375\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.9364597797393799 Validation Accuracy: 0.484375\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.9667643308639526 Validation Accuracy: 0.48046875\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.8639804720878601 Validation Accuracy: 0.498046875\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.9568023085594177 Validation Accuracy: 0.482421875\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.8339902758598328 Validation Accuracy: 0.517578125\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.8141826391220093 Validation Accuracy: 0.517578125\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.8141648769378662 Validation Accuracy: 0.515625\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.775787889957428 Validation Accuracy: 0.51171875\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.7532889246940613 Validation Accuracy: 0.521484375\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.7546366453170776 Validation Accuracy: 0.505859375\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.722564697265625 Validation Accuracy: 0.521484375\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.6938294172286987 Validation Accuracy: 0.51953125\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.6743248105049133 Validation Accuracy: 0.529296875\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.6642212867736816 Validation Accuracy: 0.517578125\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.638697624206543 Validation Accuracy: 0.521484375\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.6391646265983582 Validation Accuracy: 0.525390625\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.6557802557945251 Validation Accuracy: 0.505859375\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.6113006472587585 Validation Accuracy: 0.53515625\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.6173058748245239 Validation Accuracy: 0.529296875\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.5714117884635925 Validation Accuracy: 0.5390625\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.5332039594650269 Validation Accuracy: 0.54296875\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.523231565952301 Validation Accuracy: 0.5390625\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.5132417678833008 Validation Accuracy: 0.525390625\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.2083544731140137 Validation Accuracy: 0.150390625\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 1.9909745454788208 Validation Accuracy: 0.232421875\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 1.8273814916610718 Validation Accuracy: 0.27734375\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 1.7710989713668823 Validation Accuracy: 0.314453125\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 1.777341365814209 Validation Accuracy: 0.318359375\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 1.8111097812652588 Validation Accuracy: 0.33984375\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 1.6608545780181885 Validation Accuracy: 0.375\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 1.4600822925567627 Validation Accuracy: 0.37890625\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 1.525176763534546 Validation Accuracy: 0.392578125\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 1.5676279067993164 Validation Accuracy: 0.39453125\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.6352152824401855 Validation Accuracy: 0.412109375\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 1.5300167798995972 Validation Accuracy: 0.4140625\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 1.3321378231048584 Validation Accuracy: 0.42578125\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 1.3969578742980957 Validation Accuracy: 0.443359375\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.4679360389709473 Validation Accuracy: 0.435546875\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.4959098100662231 Validation Accuracy: 0.46875\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 1.4578361511230469 Validation Accuracy: 0.4609375\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 1.260283350944519 Validation Accuracy: 0.47265625\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 1.316680908203125 Validation Accuracy: 0.47265625\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 1.3778802156448364 Validation Accuracy: 0.453125\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.418260931968689 Validation Accuracy: 0.486328125\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 1.3619555234909058 Validation Accuracy: 0.5078125\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 1.1956980228424072 Validation Accuracy: 0.490234375\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 1.2404289245605469 Validation Accuracy: 0.48828125\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 1.3022315502166748 Validation Accuracy: 0.484375\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.3570103645324707 Validation Accuracy: 0.490234375\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 1.2877264022827148 Validation Accuracy: 0.509765625\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 1.1550133228302002 Validation Accuracy: 0.484375\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 1.1683237552642822 Validation Accuracy: 0.5078125\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 1.240100383758545 Validation Accuracy: 0.498046875\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.2816240787506104 Validation Accuracy: 0.5234375\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 1.2333115339279175 Validation Accuracy: 0.51953125\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 1.1146643161773682 Validation Accuracy: 0.494140625\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 1.144162654876709 Validation Accuracy: 0.537109375\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 1.1808005571365356 Validation Accuracy: 0.517578125\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.2362056970596313 Validation Accuracy: 0.533203125\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 1.1871812343597412 Validation Accuracy: 0.54296875\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 1.0908536911010742 Validation Accuracy: 0.5234375\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 1.097015619277954 Validation Accuracy: 0.556640625\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 1.1410480737686157 Validation Accuracy: 0.529296875\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.184468150138855 Validation Accuracy: 0.552734375\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 1.1518086194992065 Validation Accuracy: 0.5546875\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 1.067166805267334 Validation Accuracy: 0.5625\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 1.0339388847351074 Validation Accuracy: 0.568359375\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 1.0839903354644775 Validation Accuracy: 0.55859375\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.1659096479415894 Validation Accuracy: 0.5625\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 1.1056143045425415 Validation Accuracy: 0.568359375\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 0.9960906505584717 Validation Accuracy: 0.5625\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 0.9970518350601196 Validation Accuracy: 0.57421875\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 1.0456749200820923 Validation Accuracy: 0.5625\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.1116197109222412 Validation Accuracy: 0.578125\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 1.0839958190917969 Validation Accuracy: 0.583984375\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 0.9626051187515259 Validation Accuracy: 0.57421875\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 0.9779106974601746 Validation Accuracy: 0.583984375\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 1.014120101928711 Validation Accuracy: 0.57421875\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.068040370941162 Validation Accuracy: 0.595703125\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 1.0556602478027344 Validation Accuracy: 0.591796875\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 0.9261096715927124 Validation Accuracy: 0.587890625\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 0.9609577655792236 Validation Accuracy: 0.595703125\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 0.9796254634857178 Validation Accuracy: 0.587890625\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.0463147163391113 Validation Accuracy: 0.6015625\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 1.049302101135254 Validation Accuracy: 0.59375\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 0.8898283243179321 Validation Accuracy: 0.58203125\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 0.9286625385284424 Validation Accuracy: 0.587890625\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 0.9484125375747681 Validation Accuracy: 0.5859375\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.0198951959609985 Validation Accuracy: 0.609375\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 1.0157026052474976 Validation Accuracy: 0.60546875\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 0.8691146373748779 Validation Accuracy: 0.572265625\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 0.895712673664093 Validation Accuracy: 0.59765625\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 0.9188008308410645 Validation Accuracy: 0.591796875\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 0.9830774664878845 Validation Accuracy: 0.611328125\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 0.997994065284729 Validation Accuracy: 0.6171875\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 0.85152667760849 Validation Accuracy: 0.59765625\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 0.8615156412124634 Validation Accuracy: 0.61328125\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 0.8738178014755249 Validation Accuracy: 0.607421875\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 0.949679434299469 Validation Accuracy: 0.615234375\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 0.968243420124054 Validation Accuracy: 0.625\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 0.8282244801521301 Validation Accuracy: 0.595703125\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 0.8475965261459351 Validation Accuracy: 0.62890625\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 0.850148618221283 Validation Accuracy: 0.619140625\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.9352829456329346 Validation Accuracy: 0.625\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 0.9547842741012573 Validation Accuracy: 0.634765625\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 0.8118831515312195 Validation Accuracy: 0.6015625\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 0.8238937258720398 Validation Accuracy: 0.611328125\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 0.833208441734314 Validation Accuracy: 0.619140625\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.9034150838851929 Validation Accuracy: 0.62109375\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 0.9319757223129272 Validation Accuracy: 0.638671875\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 0.7765272855758667 Validation Accuracy: 0.603515625\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 0.8074368834495544 Validation Accuracy: 0.615234375\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 0.802667498588562 Validation Accuracy: 0.625\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.8879488110542297 Validation Accuracy: 0.62890625\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 0.9219839572906494 Validation Accuracy: 0.642578125\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 0.7644101977348328 Validation Accuracy: 0.607421875\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 0.7917542457580566 Validation Accuracy: 0.61328125\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 0.7951099276542664 Validation Accuracy: 0.625\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.859843909740448 Validation Accuracy: 0.62890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 0.8773765563964844 Validation Accuracy: 0.65234375\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 0.7330131530761719 Validation Accuracy: 0.615234375\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 0.7917156219482422 Validation Accuracy: 0.615234375\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 0.7751041650772095 Validation Accuracy: 0.638671875\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.8411970138549805 Validation Accuracy: 0.62890625\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 0.8905455470085144 Validation Accuracy: 0.630859375\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 0.7091881632804871 Validation Accuracy: 0.619140625\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 0.7705798149108887 Validation Accuracy: 0.634765625\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 0.740945041179657 Validation Accuracy: 0.6328125\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.8237161636352539 Validation Accuracy: 0.634765625\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 0.8704664707183838 Validation Accuracy: 0.634765625\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 0.695601761341095 Validation Accuracy: 0.634765625\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 0.7480503916740417 Validation Accuracy: 0.642578125\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 0.7285053133964539 Validation Accuracy: 0.640625\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.7968446016311646 Validation Accuracy: 0.64453125\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 0.8628663420677185 Validation Accuracy: 0.638671875\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 0.6678459644317627 Validation Accuracy: 0.634765625\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 0.7526167631149292 Validation Accuracy: 0.64453125\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 0.7269635796546936 Validation Accuracy: 0.640625\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.798628568649292 Validation Accuracy: 0.6484375\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 0.8273405432701111 Validation Accuracy: 0.658203125\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 0.6586530804634094 Validation Accuracy: 0.625\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 0.718701183795929 Validation Accuracy: 0.640625\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 0.7044472098350525 Validation Accuracy: 0.64453125\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.7872461080551147 Validation Accuracy: 0.65234375\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 0.7911980152130127 Validation Accuracy: 0.650390625\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 0.6492289900779724 Validation Accuracy: 0.619140625\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 0.6785242557525635 Validation Accuracy: 0.62890625\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 0.6952312588691711 Validation Accuracy: 0.63671875\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.7403391003608704 Validation Accuracy: 0.640625\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 0.7729647159576416 Validation Accuracy: 0.6640625\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 0.635398268699646 Validation Accuracy: 0.615234375\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 0.6650587916374207 Validation Accuracy: 0.64453125\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 0.6701878905296326 Validation Accuracy: 0.638671875\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.7443681955337524 Validation Accuracy: 0.630859375\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 0.7558764815330505 Validation Accuracy: 0.6640625\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 0.6337054967880249 Validation Accuracy: 0.6171875\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 0.6465588212013245 Validation Accuracy: 0.64453125\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 0.667291522026062 Validation Accuracy: 0.638671875\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.7113686800003052 Validation Accuracy: 0.654296875\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 0.71792072057724 Validation Accuracy: 0.658203125\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 0.590671181678772 Validation Accuracy: 0.642578125\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 0.6251264214515686 Validation Accuracy: 0.66015625\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 0.6526439189910889 Validation Accuracy: 0.646484375\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.715071976184845 Validation Accuracy: 0.662109375\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 0.7064367532730103 Validation Accuracy: 0.66796875\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 0.5882217288017273 Validation Accuracy: 0.62109375\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 0.599736213684082 Validation Accuracy: 0.6640625\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 0.6259085536003113 Validation Accuracy: 0.642578125\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.676339328289032 Validation Accuracy: 0.671875\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 0.683648407459259 Validation Accuracy: 0.673828125\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 0.5678431987762451 Validation Accuracy: 0.646484375\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 0.5825261473655701 Validation Accuracy: 0.6640625\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 0.6205266714096069 Validation Accuracy: 0.66015625\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.6688786745071411 Validation Accuracy: 0.662109375\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 0.6719253659248352 Validation Accuracy: 0.66015625\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 0.5597141981124878 Validation Accuracy: 0.634765625\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 0.5806388854980469 Validation Accuracy: 0.677734375\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 0.5957309007644653 Validation Accuracy: 0.6640625\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.6499051451683044 Validation Accuracy: 0.658203125\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 0.6640182733535767 Validation Accuracy: 0.666015625\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 0.5664613246917725 Validation Accuracy: 0.623046875\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 0.5585235953330994 Validation Accuracy: 0.6640625\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 0.5940154790878296 Validation Accuracy: 0.662109375\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.6249654293060303 Validation Accuracy: 0.662109375\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 0.6709206104278564 Validation Accuracy: 0.6875\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 0.5327960848808289 Validation Accuracy: 0.63671875\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 0.5453547835350037 Validation Accuracy: 0.671875\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 0.5918252468109131 Validation Accuracy: 0.666015625\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.6347418427467346 Validation Accuracy: 0.658203125\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 0.6681559681892395 Validation Accuracy: 0.650390625\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 0.5116316676139832 Validation Accuracy: 0.6484375\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 0.5578007698059082 Validation Accuracy: 0.6796875\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 0.5764559507369995 Validation Accuracy: 0.669921875\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.6331053376197815 Validation Accuracy: 0.65625\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 0.7277128100395203 Validation Accuracy: 0.599609375\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 0.5283486843109131 Validation Accuracy: 0.66015625\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 0.5563981533050537 Validation Accuracy: 0.6640625\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 0.5737837553024292 Validation Accuracy: 0.669921875\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.6317235827445984 Validation Accuracy: 0.66015625\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 0.6957821846008301 Validation Accuracy: 0.607421875\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 0.5193766355514526 Validation Accuracy: 0.66796875\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 0.5561259984970093 Validation Accuracy: 0.658203125\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 0.5999883413314819 Validation Accuracy: 0.671875\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.6443691849708557 Validation Accuracy: 0.6640625\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 0.7726841568946838 Validation Accuracy: 0.580078125\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 0.5605946779251099 Validation Accuracy: 0.646484375\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 0.5693590044975281 Validation Accuracy: 0.64453125\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 0.5899670124053955 Validation Accuracy: 0.677734375\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.6001990437507629 Validation Accuracy: 0.66796875\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 0.679092526435852 Validation Accuracy: 0.638671875\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 0.5390996336936951 Validation Accuracy: 0.673828125\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 0.53825843334198 Validation Accuracy: 0.6640625\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 0.5687095522880554 Validation Accuracy: 0.673828125\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.5948655605316162 Validation Accuracy: 0.669921875\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 0.6664848327636719 Validation Accuracy: 0.66015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 0.5278714895248413 Validation Accuracy: 0.65234375\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 0.5101841688156128 Validation Accuracy: 0.669921875\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 0.5614245533943176 Validation Accuracy: 0.671875\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.5581154823303223 Validation Accuracy: 0.671875\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 0.6311224102973938 Validation Accuracy: 0.6640625\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 0.4938930571079254 Validation Accuracy: 0.671875\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 0.49726712703704834 Validation Accuracy: 0.662109375\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 0.5553927421569824 Validation Accuracy: 0.68359375\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.5645456910133362 Validation Accuracy: 0.65625\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 0.6227644085884094 Validation Accuracy: 0.658203125\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 0.5035611391067505 Validation Accuracy: 0.6875\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 0.49514132738113403 Validation Accuracy: 0.669921875\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 0.5907860398292542 Validation Accuracy: 0.66015625\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.5304455757141113 Validation Accuracy: 0.673828125\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 0.5935010313987732 Validation Accuracy: 0.6875\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 0.468738853931427 Validation Accuracy: 0.697265625\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 0.49208301305770874 Validation Accuracy: 0.66015625\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 0.5779116153717041 Validation Accuracy: 0.6640625\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.5310999155044556 Validation Accuracy: 0.673828125\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 0.6017025709152222 Validation Accuracy: 0.6796875\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 0.4687288999557495 Validation Accuracy: 0.671875\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 0.4886297881603241 Validation Accuracy: 0.658203125\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 0.5715486407279968 Validation Accuracy: 0.65625\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.5257055163383484 Validation Accuracy: 0.67578125\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 0.6168927550315857 Validation Accuracy: 0.671875\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 0.476887583732605 Validation Accuracy: 0.671875\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 0.5124906897544861 Validation Accuracy: 0.630859375\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 0.5338316559791565 Validation Accuracy: 0.654296875\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.5219355821609497 Validation Accuracy: 0.66796875\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 0.5887961387634277 Validation Accuracy: 0.67578125\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 0.4692944884300232 Validation Accuracy: 0.677734375\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 0.4816880226135254 Validation Accuracy: 0.666015625\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 0.5547956228256226 Validation Accuracy: 0.65625\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.5221227407455444 Validation Accuracy: 0.6796875\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 0.6168949604034424 Validation Accuracy: 0.67578125\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 0.4548998475074768 Validation Accuracy: 0.685546875\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 0.4836626648902893 Validation Accuracy: 0.66796875\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 0.5771358013153076 Validation Accuracy: 0.66796875\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.5633059740066528 Validation Accuracy: 0.681640625\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 0.6059709787368774 Validation Accuracy: 0.666015625\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 0.4402100443840027 Validation Accuracy: 0.6875\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 0.47659268975257874 Validation Accuracy: 0.671875\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 0.5211094617843628 Validation Accuracy: 0.6953125\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.51600581407547 Validation Accuracy: 0.66015625\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 0.6045182347297668 Validation Accuracy: 0.66796875\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 0.43168652057647705 Validation Accuracy: 0.6875\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 0.4620131850242615 Validation Accuracy: 0.673828125\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 0.501114547252655 Validation Accuracy: 0.677734375\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.4967941641807556 Validation Accuracy: 0.6640625\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 0.5674187541007996 Validation Accuracy: 0.677734375\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 0.4246724545955658 Validation Accuracy: 0.673828125\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 0.44658541679382324 Validation Accuracy: 0.671875\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 0.48669523000717163 Validation Accuracy: 0.6796875\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.5035108923912048 Validation Accuracy: 0.666015625\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 0.5524916052818298 Validation Accuracy: 0.67578125\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 0.41391459107398987 Validation Accuracy: 0.677734375\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 0.42965781688690186 Validation Accuracy: 0.6875\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 0.4708496928215027 Validation Accuracy: 0.662109375\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.46897733211517334 Validation Accuracy: 0.677734375\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 0.529556155204773 Validation Accuracy: 0.658203125\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 0.3976418077945709 Validation Accuracy: 0.6953125\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 0.41211843490600586 Validation Accuracy: 0.689453125\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 0.4538190960884094 Validation Accuracy: 0.685546875\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.4583062529563904 Validation Accuracy: 0.671875\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 0.5342358350753784 Validation Accuracy: 0.6796875\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 0.39002832770347595 Validation Accuracy: 0.693359375\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 0.40793412923812866 Validation Accuracy: 0.689453125\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 0.4413309097290039 Validation Accuracy: 0.673828125\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.43875086307525635 Validation Accuracy: 0.681640625\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 0.5098029971122742 Validation Accuracy: 0.669921875\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 0.3794451951980591 Validation Accuracy: 0.6875\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 0.3840683102607727 Validation Accuracy: 0.69921875\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 0.4386816620826721 Validation Accuracy: 0.662109375\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.42378926277160645 Validation Accuracy: 0.681640625\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 0.47873327136039734 Validation Accuracy: 0.6796875\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 0.3822765350341797 Validation Accuracy: 0.681640625\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 0.3912833631038666 Validation Accuracy: 0.68359375\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 0.431895911693573 Validation Accuracy: 0.67578125\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.40831199288368225 Validation Accuracy: 0.69140625\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 0.4869680106639862 Validation Accuracy: 0.685546875\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 0.36361438035964966 Validation Accuracy: 0.68359375\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 0.38989368081092834 Validation Accuracy: 0.685546875\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 0.4314010739326477 Validation Accuracy: 0.673828125\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.40612053871154785 Validation Accuracy: 0.6953125\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 0.4801425039768219 Validation Accuracy: 0.681640625\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 0.3852994441986084 Validation Accuracy: 0.685546875\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 0.3889502286911011 Validation Accuracy: 0.693359375\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 0.4230680763721466 Validation Accuracy: 0.685546875\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.40003615617752075 Validation Accuracy: 0.6875\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 0.46596819162368774 Validation Accuracy: 0.685546875\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 0.3782695233821869 Validation Accuracy: 0.689453125\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 0.3953022360801697 Validation Accuracy: 0.677734375\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 0.4260658919811249 Validation Accuracy: 0.67578125\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.40535813570022583 Validation Accuracy: 0.705078125\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 0.46071624755859375 Validation Accuracy: 0.6640625\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 0.3640584945678711 Validation Accuracy: 0.6796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 0.3888891935348511 Validation Accuracy: 0.693359375\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 0.4245573580265045 Validation Accuracy: 0.6640625\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.41172027587890625 Validation Accuracy: 0.701171875\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 0.4386975169181824 Validation Accuracy: 0.6640625\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 0.3453386723995209 Validation Accuracy: 0.685546875\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 0.38202735781669617 Validation Accuracy: 0.701171875\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 0.4049965739250183 Validation Accuracy: 0.677734375\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.42068105936050415 Validation Accuracy: 0.689453125\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 0.43754297494888306 Validation Accuracy: 0.6875\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 0.34829598665237427 Validation Accuracy: 0.68359375\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 0.37674176692962646 Validation Accuracy: 0.673828125\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 0.4317013621330261 Validation Accuracy: 0.681640625\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.6586569428443909\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efdf06ec588>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
